# SnapKV å®Œæ•´è°ƒç”¨é“¾è¯¦è§£


## ç¬¬ä¸€éƒ¨åˆ†ï¼šè¯„ä¼°æµç¨‹å¯åŠ¨ (`evaluation/evaluate.py`)

### 0ï¸âƒ£ **å…¥å£å‡½æ•°** - `EvaluationRunner.run_evaluation()`
```python
def run_evaluation(self):
    """è¯„ä¼°çš„ä¸»å…¥å£å‡½æ•°ï¼Œåè°ƒæ•´ä¸ªè¯„ä¼°æµç¨‹"""
    output_dir = self._setup_directories()           # â‘  åˆ›å»ºè¾“å‡ºç›®å½•
    results_dir = self.config.get_results_dir(...)   # â‘¡ è·å–ç»“æœä¿å­˜è·¯å¾„
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç»“æœï¼Œé¿å…é‡å¤è¯„ä¼°
    if predictions_filename.exists() and metrics_filename.exists():
        return
    
    self._setup_press()                              # â‘¢ åˆå§‹åŒ– Pressï¼ˆSnapKVï¼‰
    self._setup_model_pipeline()                     # â‘£ åŠ è½½æ¨¡å‹å’Œ Pipeline
    self._load_and_prepare_dataset()                 # â‘¤ åŠ è½½æ•°æ®é›†
    
    self._run_inference()                            # â‘¥ ğŸ”¥ æ ¸å¿ƒæ¨ç†ï¼ˆè°ƒç”¨ SnapKVï¼‰
    self._save_results(predictions_filename)         # â‘¦ ä¿å­˜é¢„æµ‹ç»“æœ
    self._calculate_and_save_metrics(...)            # â‘§ è®¡ç®—å¹¶ä¿å­˜æŒ‡æ ‡
    self.config.save_config(config_filename)         # â‘¨ ä¿å­˜é…ç½®æ–‡ä»¶
```

**ä½œç”¨**: æ€»æŒ‡æŒ¥ï¼ŒæŒ‰é¡ºåºè°ƒç”¨æ‰€æœ‰å­å‡½æ•°å®Œæˆè¯„ä¼°ã€‚

---

### â‘  `_setup_directories()`
```python
def _setup_directories(self) -> Path:
    output_dir = Path(self.config.output_dir)  # é»˜è®¤ "./results"
    output_dir.mkdir(parents=True, exist_ok=True)
    return output_dir
```
**ä½œç”¨**: åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚ `./results`ï¼‰ï¼Œç”¨äºä¿å­˜è¯„ä¼°ç»“æœã€‚

---

### â‘¡ `get_results_dir(output_dir)`
```python
def get_results_dir(self, output_dir: Path) -> Path:
    # æ ¹æ®é…ç½®å‚æ•°ç”Ÿæˆå”¯ä¸€çš„ç»“æœå­ç›®å½•
    # æ ¼å¼ï¼šdataset__model__press__compression_ratio
    # ä¾‹å¦‚ï¼šlongbench-e__hotpotqa_e__Meta-Llama-3.1-8B-Instruct__snapkv__0.50
    components = [
        self.dataset,                    # "longbench-e"
        self.model.replace("/", "--"),   # "Meta-Llama-3.1-8B-Instruct"
        self.press_name,                 # "snapkv"
        f"{self.compression_ratio:.2f}", # "0.50"
    ]
    dir_name = "__".join(filter(None, components))
    config_dir = output_dir / dir_name
    config_dir.mkdir(parents=True, exist_ok=True)
    return config_dir
```
**ä½œç”¨**: ä¸ºæœ¬æ¬¡è¯„ä¼°åˆ›å»ºå”¯ä¸€çš„å­ç›®å½•ï¼Œé¿å…ä¸åŒé…ç½®çš„ç»“æœç›¸äº’è¦†ç›–ã€‚

---

### â‘¢ `_setup_press()`
```python
def _setup_press(self):
    press = PRESS_REGISTRY[self.config.press_name]  # è·å– SnapKVPress å®ä¾‹
    
    # ä¸º SnapKV è®¾ç½®å‹ç¼©ç‡ï¼ˆå¦‚ 0.5 è¡¨ç¤ºä¿ç•™ 50% çš„ Tokenï¼‰
    if hasattr(press, "compression_ratio"):
        press.compression_ratio = self.config.compression_ratio
    
    self.press = press
```
**ä½œç”¨**: åˆå§‹åŒ– SnapKV Pressï¼Œè®¾ç½®å‹ç¼©ç‡å‚æ•°ï¼ˆä¾‹å¦‚ä» `debug_config.yaml` è¯»å–çš„ 0.5ï¼‰ã€‚

**å…³é”®**: è¿™é‡Œåˆ›å»ºçš„ `press` å¯¹è±¡ä¼šåœ¨ç¬¬ â‘¥ æ­¥ä¼ å…¥ Pipelineã€‚

---

### â‘£ `_setup_model_pipeline()`
```python
def _setup_model_pipeline(self):
    model_name = self.config.model  # "/NV1/ykw/models/Meta-Llama-3.1-8B-Instruct"
    device = self.config.device or "auto"
    
    # åŠ è½½æˆ‘ä»¬è‡ªå®šä¹‰çš„ Pipelineï¼ˆæ³¨å†Œåœ¨ kvpress/pipeline.py ä¸­ï¼‰
    self.pipeline = pipeline(
        "kv-press-text-generation",  # è‡ªå®šä¹‰ Pipeline åç§°
        model=model_name,
        device=device,
        model_kwargs={...}
    )
    self.pipeline.model.eval()
```
**ä½œç”¨**: 
- åŠ è½½ Llama æ¨¡å‹å’Œ Tokenizer
- åˆ›å»º `KVPressTextGenerationPipeline` å®ä¾‹ï¼ˆæˆ‘ä»¬è‡ªå®šä¹‰çš„ Pipelineï¼‰
- å°†æ¨¡å‹è®¾ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆ`eval()`ï¼‰

**å…³é”®**: è¿™ä¸ª Pipeline ä¼šæ¥æ”¶ Press å¯¹è±¡ï¼Œå¹¶åœ¨æ¨ç†æ—¶æ¿€æ´» KV å‹ç¼©ã€‚

---

### â‘¤ `_load_and_prepare_dataset()`
```python
def _load_and_prepare_dataset(self):
    dataset_name = self.config.dataset  # "longbench-e"
    data_dir = self.config.data_dir     # "hotpotqa_e"
    
    # ä» HuggingFace åŠ è½½æ•°æ®é›†
    df = load_dataset(DATASET_REGISTRY[dataset_name], data_dir=data_dir, split="test").to_pandas()
    
    # å¦‚æœè®¾ç½®äº† fraction < 1.0ï¼Œåˆ™éšæœºé‡‡æ ·ï¼ˆç”¨äºå¿«é€Ÿè°ƒè¯•ï¼‰
    if self.config.fraction < 1.0:
        df = df.sample(frac=self.config.fraction, random_state=self.config.seed)
    
    # å¦‚æœå¯ç”¨ query_awareï¼Œå°†é—®é¢˜æ‹¼æ¥åˆ° context åé¢
    if self.config.query_aware:
        df["context"] = df["context"] + df["question"]
        df["question"] = ""
    
    self.df = df
```
**ä½œç”¨**: 
- åŠ è½½è¯„ä¼°æ•°æ®é›†ï¼ˆå¦‚ LongBench-E çš„ HotpotQA å­ä»»åŠ¡ï¼‰
- åº”ç”¨é‡‡æ ·ï¼ˆ`fraction=0.01` è¡¨ç¤ºåªç”¨ 1% æ•°æ®å¿«é€Ÿæµ‹è¯•ï¼‰
- å¤„ç†æŸ¥è¯¢æ„ŸçŸ¥å‹ç¼©ï¼ˆå°†é—®é¢˜æ‹¼æ¥åˆ°ä¸Šä¸‹æ–‡ï¼‰

**æ•°æ®æ ¼å¼**:
```python
df = pd.DataFrame({
    "context": ["é•¿æ–‡æœ¬1", "é•¿æ–‡æœ¬2", ...],      # è¾“å…¥ä¸Šä¸‹æ–‡ï¼ˆå¦‚ä¸€ç¯‡é•¿æ–‡æ¡£ï¼‰
    "question": ["é—®é¢˜1", "é—®é¢˜2", ...],        # éœ€è¦å›ç­”çš„é—®é¢˜
    "answer": ["ç­”æ¡ˆ1", "ç­”æ¡ˆ2", ...],          # æ­£ç¡®ç­”æ¡ˆï¼ˆç”¨äºè¯„ä¼°ï¼‰
    "max_new_tokens": [50, 50, ...],           # æ¯ä¸ªé—®é¢˜çš„æœ€å¤§ç”Ÿæˆé•¿åº¦
    "answer_prefix": ["", "", ...],            # ç­”æ¡ˆå‰ç¼€ï¼ˆå¯é€‰ï¼‰
})
```

---

### â‘¥ `_run_inference()` ğŸ”¥ **æ ¸å¿ƒæ¨ç†å‡½æ•°**
```python
@torch.inference_mode()
def _run_inference(self):
    self.df["predicted_answer"] = None
    
    # æŒ‰ context åˆ†ç»„ï¼ˆåŒä¸€ä¸ª context å¯èƒ½æœ‰å¤šä¸ªé—®é¢˜ï¼‰
    df_context_grouped = self.df.groupby("context")
    
    for context, df_group in tqdm(df_context_grouped, desc="Running Inference"):
        questions = df_group["question"].to_list()
        max_new_tokens = self.config.max_new_tokens or df_group["max_new_tokens"].iloc[0]
        answer_prefix = df_group["answer_prefix"].iloc[0]
        
        # ğŸ¯ è°ƒç”¨ Pipelineï¼ˆè¿™é‡Œä¼šè§¦å‘ SnapKV å‹ç¼©ï¼‰
        output = self.pipeline(
            context,                                # é•¿æ–‡æœ¬è¾“å…¥
            questions=questions,                    # é—®é¢˜åˆ—è¡¨
            answer_prefix=answer_prefix,            # ç­”æ¡ˆå‰ç¼€
            press=self.press,                       # SnapKVPress å®ä¾‹
            max_new_tokens=max_new_tokens,          # æœ€å¤§ç”Ÿæˆé•¿åº¦
            max_context_length=self.config.max_context_length,
        )
        
        # ä¿å­˜é¢„æµ‹ç»“æœ
        self.df.loc[df_group.index, "predicted_answer"] = output["answers"]
        self.df.loc[df_group.index, "compression_ratio"] = self.press.compression_ratio
        
        torch.cuda.empty_cache()  # æ¸…ç†æ˜¾å­˜
```
**ä½œç”¨**: 
- éå†æ•°æ®é›†ä¸­çš„æ¯ä¸ª context
- è°ƒç”¨ `self.pipeline()` è¿›è¡Œæ¨ç†ï¼ˆ**è¿™ä¸€æ­¥ä¼šè§¦å‘ SnapKV çš„ KV å‹ç¼©**ï¼‰
- ä¿å­˜æ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆ

**å…³é”®ç‚¹**:
- **ç›¸åŒ context çš„å¤šä¸ªé—®é¢˜åªéœ€è¦å¤„ç†ä¸€æ¬¡ context**ï¼ˆå…±äº«å‹ç¼©åçš„ KV Cacheï¼‰
- `self.pipeline()` å†…éƒ¨ä¼šè°ƒç”¨ `_forward()` æ–¹æ³•ï¼ˆè§ä¸‹ä¸€éƒ¨åˆ†ï¼‰

---

### â‘¦ `_save_results(predictions_filename)`
```python
def _save_results(self, save_filename: Path):
    # ä¿å­˜é¢„æµ‹ç»“æœåˆ° CSV æ–‡ä»¶
    self.df[list(set(self.df.columns) - set(["context"]))].to_csv(
        str(save_filename), index=False
    )
```
**ä½œç”¨**: å°†é¢„æµ‹ç»“æœä¿å­˜ä¸º `predictions.csv`ï¼ŒåŒ…å«é—®é¢˜ã€çœŸå®ç­”æ¡ˆã€é¢„æµ‹ç­”æ¡ˆã€å‹ç¼©ç‡ç­‰ã€‚

---

### â‘§ `_calculate_and_save_metrics(metrics_filename)`
```python
def _calculate_and_save_metrics(self, save_filename: Path):
    scorer = SCORER_REGISTRY[self.config.dataset]  # è·å–å¯¹åº”æ•°æ®é›†çš„è¯„åˆ†å™¨
    
    # è®¡ç®—æŒ‡æ ‡ï¼ˆå¦‚å‡†ç¡®ç‡ã€F1 åˆ†æ•°ç­‰ï¼‰
    metrics = scorer(self.df)
    
    # ä¿å­˜åˆ° JSON æ–‡ä»¶
    with open(str(save_filename), "w") as f:
        json.dump(metrics, f, indent=4)
```
**ä½œç”¨**: ä½¿ç”¨æ•°æ®é›†ç‰¹å®šçš„è¯„åˆ†å™¨è®¡ç®—æ€§èƒ½æŒ‡æ ‡ï¼ˆå¦‚ LongBench çš„ F1ã€å‡†ç¡®ç‡ç­‰ï¼‰ï¼Œä¿å­˜ä¸º `metrics.json`ã€‚

---

### â‘¨ `save_config(config_filename)`
```python
def save_config(self, config_filename: Path):
    # å°†è¯„ä¼°é…ç½®ä¿å­˜ä¸º YAML æ–‡ä»¶
    with open(config_filename, "w") as f:
        yaml.dump(asdict(self), f, default_flow_style=False)
```
**ä½œç”¨**: ä¿å­˜æœ¬æ¬¡è¯„ä¼°çš„å®Œæ•´é…ç½®ï¼ˆæ¨¡å‹ã€æ•°æ®é›†ã€Pressã€å‹ç¼©ç‡ç­‰ï¼‰ï¼Œç¡®ä¿ç»“æœå¯å¤ç°ã€‚

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šPipeline å±‚ - KV å‹ç¼©çš„å‡†å¤‡ (`kvpress/pipeline.py`)

### 1ï¸âƒ£ **Pipeline å…¥å£** - `KVPressTextGenerationPipeline.__call__()`
```python
pipeline(context, questions=..., press=self.press, ...)
  â”‚
  â”œâ”€â†’ _sanitize_parameters()    # å‚æ•°é¢„å¤„ç†
  â”œâ”€â†’ preprocess()               # åˆ†è¯å’Œæˆªæ–­
  â”œâ”€â†’ _forward()                 # ğŸ”¥ æ ¸å¿ƒå‰å‘ä¼ æ’­ï¼ˆè¿™é‡Œè§¦å‘å‹ç¼©ï¼‰
  â””â”€â†’ postprocess()              # è§£ç ç”Ÿæˆçš„ Token
```
**ä½œç”¨**: 
- Pipeline çš„ç»Ÿä¸€å…¥å£ï¼ˆTransformers çš„æ ‡å‡† APIï¼‰
- æŒ‰é¡ºåºè°ƒç”¨é¢„å¤„ç† â†’ å‰å‘ä¼ æ’­ â†’ åå¤„ç†

---

### 2ï¸âƒ£ **å‰å‘ä¼ æ’­æ ¸å¿ƒ** - `_forward()`
```python
def _forward(self, input_tensors, max_new_tokens, press, cache):
    """
    åˆ†ä¸¤ä¸ªé˜¶æ®µï¼š
    1. Prefillï¼šå¤„ç†å®Œæ•´ contextï¼Œåº”ç”¨ SnapKV å‹ç¼© KV Cache
    2. Decodeï¼šåŸºäºå‹ç¼©åçš„ Cache ç”Ÿæˆç­”æ¡ˆï¼ˆé€å­—ç”Ÿæˆï¼‰
    """
    
    context_ids = input_tensors["context_ids"]  # åˆ†è¯åçš„ context
    cache = DynamicCache()  # åˆ›å»ºç©ºçš„ KV Cache
    
    # ========== Prefill é˜¶æ®µï¼ˆå‹ç¼© KV Cacheï¼‰ ==========
    with press(self.model):  # ğŸ¯ æ³¨å†Œ SnapKV çš„ Hook åˆ°æ‰€æœ‰å±‚
        self.model.model(
            input_ids=context_ids,      # è¾“å…¥å®Œæ•´ context
            past_key_values=cache,      # ä¼ å…¥ç©º cacheï¼Œä¼šè¢«å¡«å……
        )
    # æ­¤æ—¶ cache ä¸­å­˜å‚¨çš„æ˜¯å‹ç¼©åçš„ KVï¼ˆæ¯å±‚ 500 ä¸ª tokenï¼Œè€Œé 1000 ä¸ªï¼‰
    
    # ========== Decode é˜¶æ®µï¼ˆç”Ÿæˆç­”æ¡ˆï¼‰ ==========
    answers = []
    for question_ids in input_tensors["questions_ids"]:
        answer = self.generate_answer(
            question_ids=question_ids,   # é—®é¢˜çš„ token IDs
            cache=cache,                 # ä½¿ç”¨å‹ç¼©åçš„ cache
            context_length=context_length,
            max_new_tokens=max_new_tokens,
        )
        answers.append(answer)
    
    return answers
```

**ä½œç”¨**: 
1. **Prefill é˜¶æ®µ**: 
   - ä½¿ç”¨ `with press(self.model)` æ¿€æ´» SnapKV çš„ Hook
   - æ¨¡å‹å‰å‘ä¼ æ’­å¤„ç†å®Œæ•´ context
   - Hook åœ¨æ¯å±‚ Attention åè‡ªåŠ¨å‹ç¼© KV Cache
   - å‹ç¼©åçš„ cache é•¿åº¦ä» 1000 å‡å°‘åˆ° 500ï¼ˆå¦‚æœ compression_ratio=0.5ï¼‰

2. **Decode é˜¶æ®µ**:
   - åŸºäºå‹ç¼©åçš„ cache ç”Ÿæˆç­”æ¡ˆ
   - ä½¿ç”¨è´ªå¿ƒè§£ç ï¼ˆgreedy decodingï¼‰é€å­—ç”Ÿæˆ
   - å¯ä»¥å›ç­”å¤šä¸ªé—®é¢˜ï¼ˆå…±äº«åŒä¸€ä¸ªå‹ç¼©åçš„ cacheï¼‰

**å…³é”®ç‚¹**:
- `with press(self.model)` å†…éƒ¨è°ƒç”¨ `press.__call__(model)`ï¼Œæ³¨å†Œ Hook
- Hook ä¼šåœ¨**æ¯å±‚ Attention è®¡ç®—å®Œæˆåç«‹å³è§¦å‘**ï¼Œæ‰§è¡Œå‹ç¼©
- å‹ç¼©åªåœ¨ Prefill é˜¶æ®µæ‰§è¡Œä¸€æ¬¡ï¼ŒDecode é˜¶æ®µå¤ç”¨å‹ç¼©åçš„ç»“æœ

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šHook æ³¨å†Œä¸è§¦å‘ (`kvpress/presses/base_press.py`)

### 3ï¸âƒ£ **Hook æ³¨å†Œ** - `BasePress.__call__(model)`
```python
@contextmanager
def __call__(self, model):
    """ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼šæ³¨å†Œ Hook â†’ æ‰§è¡Œ â†’ ç§»é™¤ Hook"""
    hooks = []
    
    # éå†æ¨¡å‹çš„æ‰€æœ‰ Attention å±‚
    for name, module in model.named_modules():
        if self._is_attention(module):
            # ä¸ºæ¯å±‚æ³¨å†Œ forward_hook
            hook = module.register_forward_hook(
                self.forward_hook,  # Hook å‡½æ•°ï¼ˆä¼šåœ¨ Attention åè°ƒç”¨ï¼‰
                with_kwargs=True
            )
            hooks.append(hook)
    
    try:
        yield  # æ‰§è¡Œ with ä»£ç å—ä¸­çš„ä»£ç ï¼ˆmodel.forward()ï¼‰
    finally:
        # æ‰§è¡Œå®Œæ¯•åç§»é™¤æ‰€æœ‰ Hook
        for hook in hooks:
            hook.remove()
```
**ä½œç”¨**: 
- ä¸ºæ¨¡å‹çš„æ‰€æœ‰ Attention å±‚æ³¨å†Œ Hook
- æ¯å±‚ Attention è®¡ç®—å®Œæˆåï¼Œè‡ªåŠ¨è°ƒç”¨ `forward_hook` å‡½æ•°
- æ‰§è¡Œå®Œæ¯•åè‡ªåŠ¨æ¸…ç† Hookï¼ˆé¿å…å½±å“åç»­æ¨ç†ï¼‰

**å…³é”®**: è¿™é‡Œçš„ `yield` ä¹‹å‰æ³¨å†Œ Hookï¼Œ`yield` ä¹‹åç§»é™¤ Hookï¼Œç¡®ä¿åªåœ¨ Prefill é˜¶æ®µç”Ÿæ•ˆã€‚

---

### 4ï¸âƒ£ **Hook æ‹¦æˆªå±‚** - `BasePress.forward_hook()`
```python
def forward_hook(self, module, input, kwargs, output):
    """æ¯å±‚ Attention è®¡ç®—å®Œæˆåè‡ªåŠ¨è°ƒç”¨"""
    
    # åˆ¤æ–­æ˜¯å¦æ˜¯ Prefill é˜¶æ®µï¼ˆåªåœ¨ Prefill æ—¶å‹ç¼©ï¼‰
    cache_position = kwargs.get("cache_position")
    q_len = input[0].shape[1]  # æŸ¥è¯¢é•¿åº¦
    if cache_position is not None and cache_position[-1] >= q_len:
        return output  # Decode é˜¶æ®µï¼Œè·³è¿‡å‹ç¼©
    
    # æå–å½“å‰å±‚çš„ KV Cache
    cache = kwargs["past_key_values"]
    keys, values = extract_keys_and_values(cache, module.layer_idx)
    
    # ğŸ¯ è°ƒç”¨å­ç±»çš„ compress æ–¹æ³•ï¼ˆSnapKV ä¼šè°ƒç”¨ ScorerPress.compressï¼‰
    keys, values = self.compress(
        module,
        hidden_states=input[0],
        keys=keys,
        values=values,
        attentions=kwargs.get("attentions"),
        kwargs=kwargs,
    )
    
    # å°†å‹ç¼©åçš„ KV å†™å› Cache
    cache.update(keys, values, module.layer_idx)
    
    return output
```
**ä½œç”¨**: 
- **æ‹¦æˆªæ¯å±‚ Attention çš„è¾“å‡º**
- æå–è¯¥å±‚å®Œæ•´çš„ Keys å’Œ Values
- è°ƒç”¨ `compress` æ–¹æ³•å‹ç¼© KV
- ç”¨å‹ç¼©åçš„ KV æ›¿æ¢ Cache ä¸­çš„åŸå§‹å€¼

**è§¦å‘æ—¶æœº**: 
- âœ… **Prefill é˜¶æ®µ**: æ¯å±‚éƒ½ä¼šè§¦å‘ï¼Œæ‰§è¡Œå‹ç¼©
- âŒ **Decode é˜¶æ®µ**: è·³è¿‡ï¼ˆé€šè¿‡ `cache_position` åˆ¤æ–­ï¼‰

---

## ç¬¬å››éƒ¨åˆ†ï¼šSnapKV çš„å‹ç¼©é€»è¾‘

### 5ï¸âƒ£ **é€šç”¨å‹ç¼©å±‚** - `ScorerPress.compress()`
```python
def compress(self, module, hidden_states, keys, values, attentions, kwargs):
    """é€šç”¨çš„åŸºäºæ‰“åˆ†çš„å‹ç¼©é€»è¾‘"""
    
    k_len = keys.shape[2]  # å½“å‰å±‚çš„åºåˆ—é•¿åº¦ï¼ˆå¦‚ 1000ï¼‰
    
    # è®¡ç®—ä¿ç•™çš„ token æ•°é‡
    n_kept = int(k_len * (1 - self.compression_ratio))  # å¦‚ 1000 * 0.5 = 500
    
    # ğŸ¯ è°ƒç”¨å­ç±»çš„ score æ–¹æ³•ï¼ˆSnapKV å®ç°ï¼‰
    scores = self.score(
        module=module,
        hidden_states=hidden_states,
        keys=keys,
        values=values,
        attentions=attentions,
        kwargs=kwargs,
    )
    # scores å½¢çŠ¶: [batch_size, num_kv_heads, seq_len]
    
    # é€‰æ‹©åˆ†æ•°æœ€é«˜çš„ top-k ä¸ª token
    indices = scores.topk(n_kept, dim=-1).indices  # [batch, num_kv_heads, n_kept]
    indices = indices.sort(dim=-1).values  # ä¿æŒåŸå§‹é¡ºåº
    
    # æ ¹æ® indices æå–é‡è¦çš„ KV
    keys = keys.gather(dim=2, index=indices.unsqueeze(-1).expand(-1, -1, -1, keys.shape[-1]))
    values = values.gather(dim=2, index=indices.unsqueeze(-1).expand(-1, -1, -1, values.shape[-1]))
    
    return keys, values  # è¿”å›å‹ç¼©åçš„ KVï¼ˆé•¿åº¦ä» 1000 â†’ 500ï¼‰
```
**ä½œç”¨**: 
- æ ¹æ® `compression_ratio` è®¡ç®—éœ€è¦ä¿ç•™å¤šå°‘ token
- è°ƒç”¨ `score` å‡½æ•°ä¸ºæ¯ä¸ª token æ‰“åˆ†
- é€‰æ‹©åˆ†æ•°æœ€é«˜çš„ top-k ä¸ª token
- æå–å¯¹åº”çš„ Keys å’Œ Values

---

### 6ï¸âƒ£ **ğŸ¯ SnapKV æ ¸å¿ƒç®—æ³•** - `SnapKVPress.score()`
```python
def score(self, module, hidden_states, keys, values, attentions, kwargs):
    """
    SnapKV çš„æ ¸å¿ƒæ€æƒ³ï¼š
    ç”¨æœ€å window_size ä¸ª token çš„æ³¨æ„åŠ›åˆ†å¸ƒä½œä¸ºé‡è¦æ€§æŒ‡æ ‡
    """
    
    bsz, num_heads, q_len, head_dim = keys.shape
    window_size = self.window_size  # é»˜è®¤ 64
    
    # ========== Step 1: è®¡ç®—è§‚å¯Ÿçª—å£çš„ Attention ==========
    # åªç”¨æœ€å window_size ä¸ª token ä½œä¸º query
    query_states = hidden_states[:, -window_size:, :]  # [bsz, window_size, hidden_dim]
    
    # æŠ•å½±åˆ° query ç©ºé—´
    query_states = module.q_proj(query_states)
    query_states = query_states.view(bsz, window_size, num_heads, head_dim).transpose(1, 2)
    
    # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°: Q @ K^T
    attn_weights = torch.matmul(query_states, keys.transpose(2, 3)) / math.sqrt(head_dim)
    # attn_weights: [bsz, num_heads, window_size, q_len]
    
    # Softmax å½’ä¸€åŒ–
    attn_weights = F.softmax(attn_weights, dim=-1)
    
    # ========== Step 2: èšåˆæ³¨æ„åŠ›åˆ†æ•° ==========
    # å¯¹ window_size ç»´åº¦æ±‚å¹³å‡ï¼ˆæ¯ä¸ª token è¢«è§‚å¯Ÿçš„å¹³å‡æ³¨æ„åŠ›ï¼‰
    scores = attn_weights.mean(dim=2)  # [bsz, num_heads, q_len]
    
    return scores
```

**SnapKV æ ¸å¿ƒæ€æƒ³**:
- **å‡è®¾**: å¦‚æœä¸€ä¸ª token è¢«æœ€åå‡ ä¸ª token å…³æ³¨å¾—å¤šï¼Œè¯´æ˜å®ƒå¾ˆé‡è¦
- **å®ç°**: 
  1. ç”¨æœ€å 64 ä¸ª token ä½œä¸º query
  2. è®¡ç®—å®ƒä»¬å¯¹æ‰€æœ‰ token çš„æ³¨æ„åŠ›æƒé‡
  3. å¯¹ 64 ä¸ª query çš„æ³¨æ„åŠ›æ±‚å¹³å‡
  4. å¾—åˆ°æ¯ä¸ª token çš„é‡è¦æ€§åˆ†æ•°

**ä¸ºä»€ä¹ˆåªç”¨æœ€å 64 ä¸ª tokenï¼Ÿ**
- è®¡ç®—æ•ˆç‡ï¼šé¿å…è®¡ç®—å®Œæ•´çš„ attentionï¼ˆ1000x1000ï¼‰
- å±€éƒ¨æ€§å‡è®¾ï¼šæœ€åå‡ ä¸ª token çš„æ³¨æ„åŠ›åˆ†å¸ƒèƒ½ä»£è¡¨å…¨å±€é‡è¦æ€§

---

## ğŸ” å¸¸è§ç–‘é—®è§£ç­”

### Q1: æ˜¯å¦æ¯å±‚éƒ½å‹ç¼©ï¼Ÿ
**âœ… æ˜¯çš„**ã€‚SnapKV **ä¼šåœ¨æ¨¡å‹çš„æ¯ä¸€å±‚**éƒ½æ‰§è¡Œå‹ç¼©ï¼ˆåªè¦ `compression_ratio > 0`ï¼‰ã€‚

32 å±‚çš„æ¨¡å‹ â†’ `score()` è¢«è°ƒç”¨ 32 æ¬¡ï¼ˆæ¯å±‚ä¸€æ¬¡ï¼‰

### Q2: æœ‰æ²¡æœ‰ç¬¬ 0 å±‚ï¼Ÿ
**âœ… æœ‰**ã€‚`layer_idx` ä» **0 å¼€å§‹ç¼–å·**ï¼Œç¬¬ 0 å±‚å°±æ˜¯æ¨¡å‹çš„ç¬¬ä¸€ä¸ª Transformer Layerã€‚

ç´¢å¼•èŒƒå›´ï¼š`0, 1, 2, ..., 31`ï¼ˆå…± 32 å±‚ï¼‰

### Q3: Head ç»´åº¦å¦‚ä½•å¤„ç†ï¼Ÿ
**å¹¶è¡Œå¤„ç†**ã€‚`score` å‡½æ•°æ¥æ”¶çš„ `keys` å¼ é‡å½¢çŠ¶ä¸º `(BSZ, num_kv_heads, Seq_Len, Head_Dim)`ï¼Œä½¿ç”¨çŸ©é˜µæ“ä½œ**ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰ Head** çš„åˆ†æ•°ï¼Œè€Œéé€ Head å¾ªç¯è°ƒç”¨ã€‚

ä¾‹å¦‚ï¼šLlama 3.1 8B æœ‰ 8 ä¸ª KV Headï¼Œä¸€æ¬¡ `score()` è°ƒç”¨å°±è®¡ç®—äº† 8 ä¸ª Head çš„åˆ†æ•°ã€‚

### Q4: Prefill vs Decodeï¼Ÿ
| é˜¶æ®µ | æ˜¯å¦å‹ç¼© | è°ƒç”¨ score? | è¯´æ˜ |
|------|---------|--------------|------|
| **Prefill** | âœ… æ˜¯ | âœ… è°ƒç”¨ | å¤„ç†å®Œæ•´ contextï¼Œè®¡ç®—å¹¶å‹ç¼© KV Cache |
| **Decode** | âŒ å¦ | âŒ ä¸è°ƒç”¨ | é€å­—ç”Ÿæˆç­”æ¡ˆï¼Œå¤ç”¨å‹ç¼©åçš„ cache |

**åˆ¤æ–­ä¾æ®**: é€šè¿‡ `cache_position` å’Œ `q_len` åˆ¤æ–­æ˜¯å¦æ˜¯ Prefill é˜¶æ®µï¼š
```python
if cache_position[-1] >= q_len:
    return  # Decode é˜¶æ®µï¼Œè·³è¿‡å‹ç¼©
```

### Q5: ä¸ºä»€ä¹ˆæ¯å±‚å‹ç¼©åçš„é•¿åº¦ç›¸åŒï¼Ÿ
**âœ… æ‰€æœ‰å±‚å‹ç¼©åé•¿åº¦ç›¸åŒ**ï¼ŒåŸå› ï¼š

1. **Prefill é˜¶æ®µæ‰€æœ‰å±‚æ¥æ”¶ç›¸åŒé•¿åº¦çš„ hidden states**ï¼ˆå¦‚ 1000 ä¸ª tokenï¼‰
2. **æ¯å±‚ç‹¬ç«‹ç”Ÿæˆè‡ªå·±çš„ KV**ï¼ˆé•¿åº¦éƒ½æ˜¯ 1000ï¼‰
3. **æ‰€æœ‰å±‚ä½¿ç”¨ç›¸åŒçš„å‹ç¼©ç‡**ï¼ˆå¦‚ `compression_ratio=0.5`ï¼‰
4. **å› æ­¤æ¯å±‚çš„ `n_kept = 1000 * 0.5 = 500`**ï¼ˆä¿ç•™ 500 ä¸ªï¼‰

| å±‚çº§ | Hidden States è¾“å…¥ | ç”Ÿæˆçš„ KV é•¿åº¦ | å‹ç¼©å Cache | å­˜å‚¨ä½ç½® |
|------|------------------|---------------|-------------|---------|
| Layer 0 | 1000 | 1000 | 500 | `cache.layers[0]` |
| Layer 1 | 1000 | 1000 | 500 | `cache.layers[1]` |
| Layer 2 | 1000 | 1000 | 500 | `cache.layers[2]` |
| ... | 1000 | 1000 | 500 | ... |
| Layer 31 | 1000 | 1000 | 500 | `cache.layers[31]` |

**å…³é”®ç†è§£**: å„å±‚çš„ KV Cache æ˜¯**ç‹¬ç«‹å­˜å‚¨**çš„ï¼Œä¸æ˜¯ä»ä¸Šä¸€å±‚ç»§æ‰¿ã€‚æ¯å±‚éƒ½åŸºäºå®Œæ•´çš„ hidden states ç”Ÿæˆè‡ªå·±çš„ KVï¼Œç„¶åç‹¬ç«‹å‹ç¼©ã€‚

---

## ğŸ“Œ è°ƒç”¨é“¾æ€»ç»“

### ç²¾ç®€ç‰ˆè°ƒç”¨è·¯å¾„
```
run_evaluation()                           [è¯„ä¼°æ€»å…¥å£]
  â”‚
  â”œâ”€â†’ _setup_press()                       [åˆå§‹åŒ– SnapKVï¼Œè®¾ç½®å‹ç¼©ç‡]
  â”œâ”€â†’ _setup_model_pipeline()              [åŠ è½½æ¨¡å‹å’Œ Pipeline]
  â”œâ”€â†’ _load_and_prepare_dataset()          [åŠ è½½æ•°æ®é›†]
  â”‚
  â””â”€â†’ _run_inference()                     [ğŸ”¥ æ ¸å¿ƒæ¨ç†]
        â”‚
        â””â”€â†’ pipeline(context, press=..., questions=...)
              â”‚
              â””â”€â†’ _forward()                [Pipeline å‰å‘ä¼ æ’­]
                    â”‚
                    â”œâ”€â†’ with press(model):  [æ³¨å†Œ Hook åˆ°æ‰€æœ‰å±‚]
                    â”‚     â”‚
                    â”‚     â””â”€â†’ BasePress.__call__()
                    â”‚           â””â”€â†’ register_forward_hook() Ã— N å±‚
                    â”‚
                    â””â”€â†’ model.forward()     [æ¨¡å‹å‰å‘ä¼ æ’­]
                          â”‚
                          â””â”€â†’ for layer in layers:  [éå† 32 å±‚]
                                â”‚
                                â””â”€â†’ Attention.forward()
                                      â”‚
                                      â””â”€â†’ [è®¡ç®—å®Œ Attention åè§¦å‘ Hook]
                                            â”‚
                                            â””â”€â†’ BasePress.forward_hook()
                                                  â”‚
                                                  â””â”€â†’ ScorerPress.compress()
                                                        â”‚
                                                        â””â”€â†’ SnapKVPress.score() âœ…
                                                              â”‚
                                                              â””â”€â†’ è¿”å›é‡è¦æ€§åˆ†æ•°
```

### å…³é”®æ—¶é—´ç‚¹æ€»ç»“

| æ—¶é—´ç‚¹ | è°ƒç”¨çš„å‡½æ•° | ä½œç”¨ |
|--------|-----------|------|
| **è¯„ä¼°å¼€å§‹** | `run_evaluation()` | åè°ƒæ•´ä¸ªè¯„ä¼°æµç¨‹ |
| **åŠ è½½æ¨¡å‹** | `_setup_model_pipeline()` | åŠ è½½ Llama æ¨¡å‹å’Œ Tokenizer |
| **åˆå§‹åŒ– Press** | `_setup_press()` | åˆ›å»º SnapKVPress å®ä¾‹ï¼Œè®¾ç½®å‹ç¼©ç‡ |
| **å¼€å§‹æ¨ç†** | `_run_inference()` | éå†æ•°æ®é›†ï¼Œè°ƒç”¨ Pipeline |
| **Prefill å¼€å§‹** | `_forward()` ä¸­çš„ `with press(model)` | æ³¨å†Œ Hook åˆ°æ‰€æœ‰å±‚ |
| **æ¯å±‚ Attention å** | `forward_hook()` | æå– KVï¼Œè°ƒç”¨ compress |
| **è®¡ç®—é‡è¦æ€§** | `score()` | SnapKV çš„æ ¸å¿ƒç®—æ³•ï¼ˆæ¯å±‚è°ƒç”¨ 1 æ¬¡ï¼‰|
| **å‹ç¼© KV** | `compress()` | ä¿ç•™ top-k é‡è¦çš„ token |
| **Prefill ç»“æŸ** | Hook è‡ªåŠ¨å¸è½½ | ç§»é™¤æ‰€æœ‰ forward_hook |
| **Decode å¼€å§‹** | `generate_answer()` | åŸºäºå‹ç¼©åçš„ cache ç”Ÿæˆç­”æ¡ˆ |
| **ä¿å­˜ç»“æœ** | `_save_results()` | ä¿å­˜é¢„æµ‹ç­”æ¡ˆå’Œå‹ç¼©ç‡ |
| **è®¡ç®—æŒ‡æ ‡** | `_calculate_and_save_metrics()` | è¯„ä¼°æ¨¡å‹æ€§èƒ½ |

---

## ğŸ“ æŠ€æœ¯è¦ç‚¹æ€»ç»“

### 1. **KV Cache vs Hidden States**

| æ¦‚å¿µ | ä½œç”¨ | ä¼ é€’æ–¹å‘ | æ˜¯å¦è¢«å‹ç¼© |
|------|------|---------|-----------|
| **Hidden States** | å±‚ä¸å±‚ä¹‹é—´ä¼ é€’çš„æ¿€æ´»å€¼ | Layer N â†’ Layer N+1 | âŒ ä¸å‹ç¼©ï¼Œä¿æŒå®Œæ•´ |
| **KV Cache** | å­˜å‚¨å„å±‚çš„ Key/Valueï¼Œç”¨äº Decode åŠ é€Ÿ | å­˜å‚¨åœ¨å„å±‚å†…éƒ¨ | âœ… æ¯å±‚ç‹¬ç«‹å‹ç¼© |

### 2. **å‹ç¼©æ—¶åº**

```python
# âŒ é”™è¯¯ç†è§£ï¼ˆè¾¹è®¡ç®—è¾¹å‹ç¼©ï¼‰
Attention è®¡ç®—ä¸­... 
  â†’ ä¸€è¾¹ç”Ÿæˆ KVï¼Œä¸€è¾¹åˆ¤æ–­é‡è¦æ€§
  â†’ åªæŠŠé‡è¦çš„ Token å†™å…¥ Cache

# âœ… æ­£ç¡®æµç¨‹ï¼ˆå…ˆå®Œæ•´åå‹ç¼©ï¼‰
Step 1: Attention å®Œæ•´è®¡ç®—
  â†’ åŸºäºå®Œæ•´ hidden states ç”Ÿæˆå®Œæ•´çš„ Keys å’Œ Values
  â†’ å†™å…¥è¯¥å±‚çš„ Cache (åŒ…å«æ‰€æœ‰ Token)

Step 2: Hook ç«‹å³è§¦å‘
  â†’ ä» Cache ä¸­è¯»å–åˆšå†™å…¥çš„å®Œæ•´ KV
  â†’ è°ƒç”¨ score å‡½æ•°è®¡ç®—é‡è¦æ€§
  â†’ æŒ‘é€‰é‡è¦çš„ Tokenï¼Œä¸¢å¼ƒä¸é‡è¦çš„

Step 3: è¦†ç›–å†™å› Cache
  â†’ ç”¨å‹ç¼©åçš„ KV æ›¿æ¢å®Œæ•´ KV
  â†’ è¯¥å±‚ Cache ç°åœ¨åªåŒ…å«é‡è¦çš„ Token

Step 4: ä¼ é€’ç»™ä¸‹ä¸€å±‚
  â†’ ä¸‹ä¸€å±‚æ¥æ”¶å®Œæ•´é•¿åº¦çš„ hidden states
  â†’ ä¸‹ä¸€å±‚é‡å¤ Step 1-3
```

### 3. **ä¸ºä»€ä¹ˆè¦å‹ç¼© KV Cacheï¼Ÿ**

| ä¼˜åŠ¿ | è¯´æ˜ |
|------|------|
| **å‡å°‘æ˜¾å­˜å ç”¨** | æ¯å±‚åªå­˜å‚¨é‡è¦çš„ tokenï¼ˆå¦‚ 500 ä¸ªè€Œé 1000 ä¸ªï¼‰|
| **åŠ é€Ÿ Decode** | Decode æ—¶åªéœ€å¤„ç†å‹ç¼©åçš„ cacheï¼ˆè®¡ç®—é‡å‡åŠï¼‰|
| **ä¸å½±å“ Prefill ç²¾åº¦** | Prefill æ—¶ä»ç„¶ä½¿ç”¨å®Œæ•´åºåˆ—ï¼Œåªå‹ç¼©å­˜å‚¨çš„ cache |
| **æ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡** | å¯ä»¥åœ¨æœ‰é™æ˜¾å­˜ä¸‹å¤„ç†æ›´é•¿çš„æ–‡æœ¬ï¼ˆå¦‚ 128K tokensï¼‰|

### 4. **SnapKV çš„æ ¸å¿ƒå‡è®¾**

> **"å¦‚æœä¸€ä¸ª token è¢«æœ€åå‡ ä¸ª token å…³æ³¨å¾—å¤šï¼Œè¯´æ˜å®ƒå¾ˆé‡è¦"**

- ç”¨æœ€å 64 ä¸ª token ä½œä¸º"è§‚å¯Ÿçª—å£"
- è®¡ç®—å®ƒä»¬å¯¹æ‰€æœ‰å†å² token çš„æ³¨æ„åŠ›æƒé‡
- æ³¨æ„åŠ›æƒé‡é«˜ â†’ è¯¥ token é‡è¦ â†’ ä¿ç•™åˆ° cache ä¸­
- æ³¨æ„åŠ›æƒé‡ä½ â†’ è¯¥ token ä¸é‡è¦ â†’ ä¸¢å¼ƒ

### 5. **ä»£ç è¯æ®**

æ¥è‡ª `base_press.py` ç¬¬ 142-154 è¡Œï¼š
```python
def forward_hook(self, module, input, kwargs, output):
    # æ­¤æ—¶ Attention å·²ç»å®Œæˆè®¡ç®—ï¼Œå®Œæ•´çš„ KV å·²åœ¨ cache ä¸­
    cache = kwargs["past_key_values"]
    
    # Step 1: ä» cache ä¸­æå–å®Œæ•´çš„ keys å’Œ values
    keys, values = extract_keys_and_values(cache, module.layer_idx)
    
    # Step 2: è°ƒç”¨ compress (å†…éƒ¨è°ƒç”¨ score)ï¼Œè¿”å›å‹ç¼©åçš„ KV
    keys, values = self.compress(module, hidden_states, keys, values, ...)
    
    # Step 3: ç”¨å‹ç¼©åçš„ KV è¦†ç›– cache ä¸­çš„åŸæœ‰æ•°æ®
    cache.update(keys, values, module.layer_idx)
    
    return output  # ç»§ç»­ä¼ é€’ç»™ä¸‹ä¸€å±‚
```

---

## ğŸš€ å®Œæ•´ç¤ºä¾‹ï¼š1000 tokens â†’ 500 tokens

å‡è®¾è¾“å…¥ context æœ‰ 1000 ä¸ª tokenï¼Œæ¨¡å‹æœ‰ 32 å±‚ï¼Œ`compression_ratio=0.5`ï¼š

```
è¯„ä¼°å¼€å§‹
  â†“
åŠ è½½æ¨¡å‹: Meta-Llama-3.1-8B-Instruct (32 å±‚)
åŠ è½½æ•°æ®é›†: LongBench-E HotpotQA (åªç”¨ 1% æ•°æ®å¿«é€Ÿæµ‹è¯•)
åˆå§‹åŒ– SnapKV: compression_ratio=0.5, window_size=64
  â†“
å¼€å§‹æ¨ç†ç¬¬ 1 ä¸ª context (1000 tokens)
  â†“
Tokenize: è½¬æ¢ä¸º token IDs [101, 234, 567, ..., 999] (1000 ä¸ª)
  â†“
========== Prefill é˜¶æ®µ ==========
æ³¨å†Œ Hook åˆ° 32 å±‚
  â†“
Layer 0:
  - è¾“å…¥: hidden_states (1000 tokens)
  - ç”Ÿæˆ: keys, values (1000 tokens)
  - Hook è§¦å‘ â†’ score() è®¡ç®— â†’ ä¿ç•™ 500 ä¸ªé‡è¦ tokens
  - cache.layers[0] å­˜å‚¨: 500 tokens âœ…
  â†“
Layer 1:
  - è¾“å…¥: hidden_states (1000 tokens) â† ä»ç„¶æ˜¯å®Œæ•´çš„ï¼
  - ç”Ÿæˆ: keys, values (1000 tokens)
  - Hook è§¦å‘ â†’ score() è®¡ç®— â†’ ä¿ç•™ 500 ä¸ªé‡è¦ tokens
  - cache.layers[1] å­˜å‚¨: 500 tokens âœ…
  â†“
... Layer 2 ~ 31 é‡å¤ç›¸åŒæµç¨‹ ...
  â†“
Prefill å®Œæˆï¼Œç§»é™¤æ‰€æœ‰ Hook
æ¯å±‚ cache éƒ½åªå­˜å‚¨ 500 ä¸ª tokensï¼ˆæ€»å…±èŠ‚çœäº† 50% æ˜¾å­˜ï¼‰
  â†“
========== Decode é˜¶æ®µ ==========
æ‹¼æ¥é—®é¢˜: "What is the capital of France?"
  â†“
ç”Ÿæˆç­”æ¡ˆï¼ˆé€å­—ç”Ÿæˆï¼‰:
  Token 1: "The"   â† ä½¿ç”¨å‹ç¼©åçš„ cache (500 tokens)
  Token 2: "capital"
  Token 3: "of"
  Token 4: "France"
  Token 5: "is"
  Token 6: "Paris"
  Token 7: "."
  â†“
ç­”æ¡ˆç”Ÿæˆå®Œæ¯•: "The capital of France is Paris."
  â†“
ä¿å­˜ç»“æœåˆ° CSV å’Œ JSON
è¯„ä¼°å®Œæˆ âœ…
```

---

## ğŸ“– ç›¸å…³æ–‡ä»¶ç´¢å¼•

| æ–‡ä»¶è·¯å¾„ | å…³é”®å‡½æ•° | ä½œç”¨ |
|---------|---------|------|
| `evaluation/evaluate.py` | `run_evaluation()` | è¯„ä¼°æ€»å…¥å£ï¼Œåè°ƒæ‰€æœ‰å­æµç¨‹ |
| `evaluation/evaluate.py` | `_run_inference()` | éå†æ•°æ®é›†ï¼Œè°ƒç”¨ Pipeline æ¨ç† |
| `kvpress/pipeline.py` | `_forward()` | Pipeline æ ¸å¿ƒï¼Œè§¦å‘ Prefill å’Œ Decode |
| `kvpress/presses/base_press.py` | `__call__()` | æ³¨å†Œ Hook åˆ°æ‰€æœ‰å±‚ |
| `kvpress/presses/base_press.py` | `forward_hook()` | æ‹¦æˆª Attention è¾“å‡ºï¼Œè°ƒç”¨å‹ç¼© |
| `kvpress/presses/scorer_press.py` | `compress()` | é€šç”¨å‹ç¼©é€»è¾‘ï¼Œè°ƒç”¨å­ç±» score |
| `kvpress/presses/snapkv_press.py` | `score()` | SnapKV æ ¸å¿ƒç®—æ³•ï¼Œè®¡ç®—é‡è¦æ€§ |
| `evaluation/debug_config.yaml` | é…ç½®æ–‡ä»¶ | è®¾ç½®æ¨¡å‹ã€æ•°æ®é›†ã€å‹ç¼©ç‡ç­‰å‚æ•° |

---

## ğŸ¯ æ ¸å¿ƒç»“è®º

1. **`run_evaluation()` æ˜¯è¯„ä¼°çš„æ€»å…¥å£**ï¼ŒæŒ‰é¡ºåºè°ƒç”¨ 9 ä¸ªå­å‡½æ•°å®Œæˆè¯„ä¼°
2. **`_run_inference()` è§¦å‘æ¨ç†**ï¼Œå°† SnapKV Press ä¼ å…¥ Pipeline
3. **`_forward()` åˆ†ä¸¤é˜¶æ®µ**ï¼šPrefillï¼ˆå‹ç¼© KVï¼‰+ Decodeï¼ˆç”Ÿæˆç­”æ¡ˆï¼‰
4. **`with press(model)` æ³¨å†Œ Hook**ï¼Œåœ¨æ¯å±‚ Attention åè‡ªåŠ¨è°ƒç”¨å‹ç¼©
5. **`score()` è¢«è°ƒç”¨ N æ¬¡**ï¼ˆN = æ¨¡å‹å±‚æ•°ï¼‰ï¼Œæ¯å±‚ç‹¬ç«‹è®¡ç®—é‡è¦æ€§
6. **æ¯å±‚å‹ç¼©åé•¿åº¦ç›¸åŒ**ï¼Œå› ä¸ºè¾“å…¥é•¿åº¦ã€å‹ç¼©ç‡éƒ½ç›¸åŒ
7. **KV Cache æ¯å±‚ç‹¬ç«‹**ï¼Œä¸åŒå±‚å¯ä»¥ä¿ç•™ä¸åŒçš„é‡è¦ token
8. **å‹ç¼©åªåœ¨ Prefill é˜¶æ®µ**ï¼ŒDecode é˜¶æ®µå¤ç”¨å‹ç¼©åçš„ cache

---

## ğŸ’¡ æ‰©å±•é˜…è¯»

- **å…¶ä»– Press æ–¹æ³•**: KnormPress, ExpectedAttentionPress, BlockPress ç­‰
- **å¤šé—®é¢˜å¤„ç†**: åŒä¸€ä¸ª context å¦‚ä½•å¤ç”¨å‹ç¼©åçš„ cache å›ç­”å¤šä¸ªé—®é¢˜
- **Decoding å‹ç¼©**: DecodingPress åœ¨ç”Ÿæˆé˜¶æ®µåŠ¨æ€å‹ç¼© cache
- **æ€§èƒ½åˆ†æ**: å‹ç¼©ç‡å¯¹å‡†ç¡®ç‡å’Œé€Ÿåº¦çš„å½±å“

---

*æ–‡æ¡£ç”Ÿæˆæ—¶é—´: 2025-02-06*  
*åŸºäº KVPress ä»£ç ç‰ˆæœ¬: æœ€æ–°*

---

## â±ï¸ Prefill é˜¶æ®µçš„ç²¾ç¡®æ—¶åº

### ğŸ”‘ æ ¸å¿ƒæ¦‚å¿µï¼šKV Cache vs Hidden States

**å¿…é¡»ç†è§£çš„å…³é”®ç‚¹**ï¼š

| æ¦‚å¿µ | ä½œç”¨ | ä¼ é€’æ–¹å‘ | æ˜¯å¦è¢«å‹ç¼© |
|------|------|---------|-----------|
| **Hidden States** | å±‚ä¸å±‚ä¹‹é—´ä¼ é€’çš„æ¿€æ´»å€¼ | Layer N â†’ Layer N+1 | âŒ ä¸å‹ç¼©ï¼Œä¿æŒå®Œæ•´ |
| **KV Cache** | å­˜å‚¨å„å±‚çš„ Key/Valueï¼Œä»…ç”¨äº Decode åŠ é€Ÿ | å­˜å‚¨åœ¨å„å±‚å†…éƒ¨ | âœ… æ¯å±‚ç‹¬ç«‹å‹ç¼© |

**é”™è¯¯ç†è§£** âŒï¼š  
"Layer 0 å‹ç¼©ååªæœ‰ 500 ä¸ª tokenï¼Œæ‰€ä»¥ Layer 1 åªèƒ½çœ‹åˆ° 500 ä¸ª token"

**æ­£ç¡®ç†è§£** âœ…ï¼š  
- Layer 0 å‹ç¼©çš„æ˜¯**è‡ªå·±çš„ KV Cache**ï¼ˆå­˜å‚¨ä¸‹æ¥ç»™ Decode ç”¨ï¼‰
- Layer 1 æ¥æ”¶çš„æ˜¯ Layer 0 çš„ **Hidden States è¾“å‡º**ï¼ˆä¿æŒå®Œæ•´ 1000 ä¸ªï¼‰
- Layer 1 åŸºäºå®Œæ•´çš„ 1000 ä¸ª hidden states ç”Ÿæˆè‡ªå·±çš„ KVï¼Œç„¶åç‹¬ç«‹å‹ç¼©

---

### é‡è¦æ¾„æ¸…ï¼šå…ˆå®Œæ•´è®¡ç®—ï¼Œå†ç«‹å³å‹ç¼©

**ä½ çš„ç†è§£æ ¸å¿ƒæ­£ç¡®ï¼Œä½†æ—¶åºä¸Šæœ‰ç»†å¾®å·®åˆ«ï¼š**

#### âŒ é”™è¯¯ç†è§£ï¼ˆè¾¹è®¡ç®—è¾¹å‹ç¼©ï¼‰
```
Attention è®¡ç®—ä¸­... 
  â†’ ä¸€è¾¹ç”Ÿæˆ KVï¼Œä¸€è¾¹åˆ¤æ–­é‡è¦æ€§
  â†’ åªæŠŠé‡è¦çš„ Token å†™å…¥ Cache
```

#### âœ… æ­£ç¡®æµç¨‹ï¼ˆå…ˆå®Œæ•´åå‹ç¼©ï¼‰
```
Step 1: Attention å®Œæ•´è®¡ç®—ï¼ˆå½“å‰å±‚ï¼‰
  â†’ æ¨¡å‹åŸºäºå®Œæ•´ hidden states ç”Ÿæˆå®Œæ•´çš„ Keys å’Œ Values
  â†’ å†™å…¥è¯¥å±‚çš„ Cache (æ­¤æ—¶è¯¥å±‚ Cache åŒ…å«æ‰€æœ‰ Token)

Step 2: Hook ç«‹å³è§¦å‘ï¼ˆå½“å‰å±‚ï¼‰
  â†’ ä»è¯¥å±‚ Cache ä¸­è¯»å–åˆšå†™å…¥çš„å®Œæ•´ KV
  â†’ è°ƒç”¨ score å‡½æ•°è®¡ç®—é‡è¦æ€§
  â†’ æŒ‘é€‰é‡è¦çš„ Tokenï¼Œä¸¢å¼ƒä¸é‡è¦çš„

Step 3: è¦†ç›–å†™å› Cacheï¼ˆå½“å‰å±‚ï¼‰
  â†’ ç”¨å‹ç¼©åçš„ KV æ›¿æ¢è¯¥å±‚åŸæœ‰çš„å®Œæ•´ KV
  â†’ è¯¥å±‚ Cache ç°åœ¨åªåŒ…å«é‡è¦çš„ Token

Step 4: ä¼ é€’ç»™ä¸‹ä¸€å±‚
  â†’ ä¸‹ä¸€å±‚æ¥æ”¶å®Œæ•´é•¿åº¦çš„ hidden statesï¼ˆä¸æ˜¯ KV Cacheï¼ï¼‰
  â†’ ä¸‹ä¸€å±‚é‡å¤ Step 1-3ï¼Œç”Ÿæˆè‡ªå·±çš„å®Œæ•´ KV å¹¶ç‹¬ç«‹å‹ç¼©
  â†’ æ¯å±‚çš„ KV Cache æ˜¯ç‹¬ç«‹çš„ï¼Œäº’ä¸å½±å“
```

---

### ğŸ“ ä»£ç è¯æ® (`base_press.py` ç¬¬ 142-154 è¡Œ)

```python
def forward_hook(self, module, input, kwargs, output):
    # æ­¤æ—¶ Attention å·²ç»å®Œæˆè®¡ç®—ï¼Œå®Œæ•´çš„ KV å·²åœ¨ cache ä¸­
    cache = kwargs["past_key_values"]
    
    # Step 1: ä» cache ä¸­æå–å®Œæ•´çš„ keys å’Œ values
    keys, values = extract_keys_and_values(cache, module.layer_idx)
    
    # Step 2: è°ƒç”¨ compress (å†…éƒ¨è°ƒç”¨ score)ï¼Œè¿”å›å‹ç¼©åçš„ KV
    keys, values = self.compress(module, hidden_states, keys, values, ...)
    
    # Step 3: ç”¨å‹ç¼©åçš„ KV è¦†ç›– cache ä¸­çš„åŸæœ‰æ•°æ®
    cache_layer.keys = keys
    cache_layer.values = values
    
    return output  # ç»§ç»­ä¼ é€’ç»™ä¸‹ä¸€å±‚
```

---

### ğŸ”„ æ¯å±‚ç‹¬ç«‹å‹ç¼©æœºåˆ¶

å‡è®¾è¾“å…¥åºåˆ—æœ‰ 1000 ä¸ª Tokenï¼Œå‹ç¼©ç‡ 50%ï¼š

| å±‚çº§ | è¾“å…¥ Hidden States é•¿åº¦ | è¯¥å±‚ç”Ÿæˆçš„ KV é•¿åº¦ | å‹ç¼©å Cache é•¿åº¦ | 
|------|------------------------|-------------------|-------------------|
| **Layer 0** | 1000 | 1000 | 500 |
| **Layer 1** | 1000 | 1000 | 500 |
| **Layer 2** | 1000 | 1000 | 500 |
| ... | 1000 | 1000 | 500 |
| **Layer 31** | 1000 | 1000 | 500 |

**å…³é”®è§‚å¯Ÿ**ï¼š
- âœ… **æ¯å±‚çš„ KV Cache æ˜¯ç‹¬ç«‹çš„**ï¼ˆä¸æ˜¯ä»ä¸Šä¸€å±‚ç»§æ‰¿ï¼‰
- âœ… åœ¨ Prefill é˜¶æ®µï¼Œ**æ‰€æœ‰å±‚æ¥æ”¶ç›¸åŒé•¿åº¦çš„ hidden states**ï¼ˆ1000 ä¸ª tokenï¼‰
- âœ… **æ¯å±‚éƒ½ç”Ÿæˆå®Œæ•´é•¿åº¦çš„ KV**ï¼ˆ1000 ä¸ªï¼‰ï¼Œç„¶åç‹¬ç«‹å‹ç¼©åˆ°ç›¸åŒæ¯”ä¾‹ï¼ˆ500 ä¸ªï¼‰
- âœ… **å‹ç¼©æ¯”ä¾‹å¯¹æ‰€æœ‰å±‚ç›¸åŒ**ï¼Œæ‰€ä»¥æ¯å±‚ä¿ç•™çš„ token æ•°é‡ä¹Ÿç›¸åŒ
- âš ï¸ KV Cache åªåœ¨ **Decode é˜¶æ®µ**è¢«ä½¿ç”¨ï¼ŒPrefill é˜¶æ®µå„å±‚é—´ä¼ é€’çš„æ˜¯ hidden states

---

### ğŸ¯ å›ç­”ä½ çš„é—®é¢˜

> **æ˜¯ä¸æ˜¯ä¸€è¾¹ prefill ä¸€è¾¹è®¡ç®—å½“å‰å±‚å“ªäº› token æ¯”è¾ƒé‡è¦ï¼Ÿ**

**å‡†ç¡®ç­”æ¡ˆ**ï¼š  
ä¸æ˜¯"ä¸€è¾¹ Attention è®¡ç®—ä¸€è¾¹å‹ç¼©"ï¼Œè€Œæ˜¯ï¼š
1. **å½“å‰å±‚å…ˆå®Œæ•´è®¡ç®— Attention**ï¼ˆæ‰€æœ‰ Token éƒ½å‚ä¸ï¼‰
2. **è®¡ç®—å®Œæˆåç«‹å³è§¦å‘ Hook**
3. **Hook ä¸­è°ƒç”¨ score åˆ¤æ–­é‡è¦æ€§å¹¶å‹ç¼©è¯¥å±‚çš„ KV**
4. **å‹ç¼©ç»“æœå†™å›è¯¥å±‚ Cacheï¼Œæ›¿æ¢å®Œæ•´ç‰ˆæœ¬**
5. **ä¸‹ä¸€å±‚æ¥æ”¶å®Œæ•´çš„ hidden states**ï¼ˆä¸å—ä¸Šä¸€å±‚å‹ç¼©å½±å“ï¼‰
6. **ä¸‹ä¸€å±‚é‡å¤ 1-4 æ­¥éª¤**ï¼Œç‹¬ç«‹ç”Ÿæˆå’Œå‹ç¼©è‡ªå·±çš„ KV

> **åªå°†é‡è¦çš„ token å†™å…¥ kv ç¼“å­˜å—ï¼Ÿ**

**å‡†ç¡®ç­”æ¡ˆ**ï¼š  
ä¸æ˜¯"åªå†™å…¥é‡è¦çš„"ï¼Œè€Œæ˜¯ï¼š
1. **å…ˆå†™å…¥æ‰€æœ‰ Token çš„ KV**ï¼ˆAttention å±‚çš„æ­£å¸¸è¡Œä¸ºï¼‰
2. **ç„¶åç«‹å³ç”¨é‡è¦çš„ Token è¦†ç›–æ‰å®Œæ•´çš„ KV**ï¼ˆHook çš„ä½œç”¨ï¼‰
3. **æœ€ç»ˆè¯¥å±‚ Cache ä¸­åªå‰©ä¸‹é‡è¦çš„ Token**
4. **æ¯å±‚éƒ½æ˜¯ç‹¬ç«‹çš„**ï¼šæ¯å±‚éƒ½ç”Ÿæˆå®Œæ•´ KV â†’ å‹ç¼© â†’ å­˜å‚¨å‹ç¼©ç‰ˆæœ¬

---

### ğŸ’¡ ä¸ºä»€ä¹ˆè¦è¿™æ ·è®¾è®¡ï¼Ÿ

**æŠ€æœ¯åŸå› **ï¼š
- **Prefill é˜¶æ®µ**ï¼šæ¯å±‚éƒ½éœ€è¦è®¿é—®å®Œæ•´çš„è¾“å…¥åºåˆ—ï¼Œæ‰€ä»¥ hidden states ä¿æŒå®Œæ•´é•¿åº¦
- **Decode é˜¶æ®µ**ï¼šç”Ÿæˆæ–° token æ—¶ï¼Œéœ€è¦ä½¿ç”¨å†å² KV Cache æ¥åŠ é€Ÿè®¡ç®—
- å‹ç¼© KV Cache å¯ä»¥ï¼š
  - âœ… **å‡å°‘æ˜¾å­˜å ç”¨**ï¼ˆæ¯å±‚åªå­˜å‚¨é‡è¦çš„ KVï¼‰
  - âœ… **åŠ é€Ÿ Decode**ï¼ˆDecode æ—¶åªéœ€è¦å¤„ç†å‹ç¼©åçš„ Cacheï¼‰
  - âœ… **ä¸å½±å“ Prefill ç²¾åº¦**ï¼ˆPrefill æ—¶ä»ç„¶ä½¿ç”¨å®Œæ•´åºåˆ—ï¼‰

**å…³é”®ç†è§£**ï¼š
- **KV Cache çš„ä½œç”¨æ—¶æœº**ï¼šåªåœ¨ Decode é˜¶æ®µä½¿ç”¨ï¼Œé¿å…é‡å¤è®¡ç®—å†å² token çš„ KV
- **ä¸ºä»€ä¹ˆæ¯å±‚ç‹¬ç«‹å‹ç¼©**ï¼šå› ä¸ºæ¯å±‚çš„ KV éƒ½æ˜¯ç‹¬ç«‹ç”Ÿæˆçš„ï¼Œä¸åŒå±‚çš„é‡è¦ token å¯èƒ½ä¸åŒ
- **å‹ç¼©ä¸å½±å“å‰å‘ä¼ æ’­**ï¼šå„å±‚é—´ä¼ é€’çš„æ˜¯ hidden statesï¼ˆä¿æŒå®Œæ•´ï¼‰ï¼Œè€Œä¸æ˜¯ KV Cache

---

## ğŸ§ª ä»£ç éªŒè¯ï¼šä¸ºä»€ä¹ˆæ¯å±‚å‹ç¼©é•¿åº¦ç›¸åŒ

### å…³é”®ä»£ç è·¯å¾„

#### 1. Hook æå–å½“å‰å±‚çš„ KVï¼ˆ`base_press.py:143`ï¼‰
```python
def forward_hook(self, module, input, kwargs, output):
    # module.layer_idx æ˜¯å½“å‰å±‚çš„ç´¢å¼•ï¼ˆ0, 1, 2, ...ï¼‰
    keys, values = extract_keys_and_values(cache, module.layer_idx)
    # â†‘ æå–çš„æ˜¯å½“å‰å±‚è‡ªå·±çš„ KVï¼Œä¸æ˜¯ä¸Šä¸€å±‚çš„ï¼
```

#### 2. æå–å‡½æ•°ï¼ˆ`utils.py:104`ï¼‰
```python
def extract_keys_and_values(cache: Cache, layer_idx: int):
    # cache.layers æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œæ¯å±‚æœ‰ç‹¬ç«‹çš„ cache
    keys = cache.layers[layer_idx].keys  # å½“å‰å±‚çš„ keys
    values = cache.layers[layer_idx].values  # å½“å‰å±‚çš„ values
    return keys, values
```

#### 3. å‹ç¼©è®¡ç®—ï¼ˆ`scorer_press.py:90`ï¼‰
```python
def compress(self, module, hidden_states, keys, values, attentions, kwargs):
    # keys.shape = (batch, num_kv_heads, seq_len, head_dim)
    k_len = keys.shape[2]  # å½“å‰å±‚çš„åºåˆ—é•¿åº¦
    
    # è®¡ç®—ä¿ç•™æ•°é‡ï¼ˆæ‰€æœ‰å±‚ä½¿ç”¨ç›¸åŒçš„ compression_ratioï¼‰
    n_kept = int(k_len * (1 - self.compression_ratio))
    # â†‘ å¦‚æœ k_len å¯¹æ¯å±‚ç›¸åŒï¼Œn_kept ä¹Ÿå¯¹æ¯å±‚ç›¸åŒ
    
    scores = self.score(...)
    indices = scores.topk(n_kept, dim=-1).indices
    # é€‰æ‹© top-k ä¸ªé‡è¦çš„ token
```

### é€»è¾‘æ¨å¯¼

**Prefill é˜¶æ®µï¼ˆè¾“å…¥ 1000 ä¸ª tokenï¼Œcompression_ratio=0.5ï¼‰**ï¼š

```python
# Layer 0
hidden_states_0 = input_embeddings  # shape: (batch, 1000, hidden_dim)
keys_0, values_0 = Attention_0(hidden_states_0)  # shape: (batch, num_kv_heads, 1000, head_dim)
# Hook è§¦å‘
k_len = 1000  # keys_0.shape[2]
n_kept = int(1000 * (1 - 0.5)) = 500
compressed_keys_0 = keys_0[..., top_500_indices, :]  # å‹ç¼©åˆ° 500
cache.layers[0].keys = compressed_keys_0  # å­˜å‚¨åœ¨ Layer 0 çš„ cache ä¸­

# Layer 1
hidden_states_1 = output_from_layer_0  # shape: (batch, 1000, hidden_dim) â† ä»ç„¶æ˜¯ 1000ï¼
keys_1, values_1 = Attention_1(hidden_states_1)  # shape: (batch, num_kv_heads, 1000, head_dim)
# Hook è§¦å‘
k_len = 1000  # keys_1.shape[2] â† ä»ç„¶æ˜¯ 1000ï¼
n_kept = int(1000 * (1 - 0.5)) = 500  # â† ä»ç„¶ä¿ç•™ 500ï¼
compressed_keys_1 = keys_1[..., top_500_indices, :]  # å‹ç¼©åˆ° 500
cache.layers[1].keys = compressed_keys_1  # å­˜å‚¨åœ¨ Layer 1 çš„ cache ä¸­

# Layer 2, 3, ... 31ï¼šé‡å¤ä¸Šè¿°è¿‡ç¨‹
# æ¯å±‚éƒ½ç”Ÿæˆ 1000 ä¸ª KVï¼Œå‹ç¼©åˆ° 500 ä¸ªï¼Œå­˜å‚¨åœ¨å„è‡ªçš„ cache ä¸­
```

### æ­£ç¡®çš„å±‚çº§è¡¨æ ¼

| å±‚çº§ | Hidden States è¾“å…¥ | ç”Ÿæˆçš„ KV é•¿åº¦ | å‹ç¼©å Cache | å­˜å‚¨ä½ç½® |
|------|------------------|---------------|-------------|---------|
| Layer 0 | 1000 | 1000 | 500 | `cache.layers[0]` |
| Layer 1 | 1000 | 1000 | 500 | `cache.layers[1]` |
| Layer 2 | 1000 | 1000 | 500 | `cache.layers[2]` |
| ... | 1000 | 1000 | 500 | ... |
| Layer 31 | 1000 | 1000 | 500 | `cache.layers[31]` |

### ç»“è®º

âœ… **æ¯å±‚å‹ç¼©åçš„é•¿åº¦å®Œå…¨ç›¸åŒ**ï¼Œå› ä¸ºï¼š
1. Prefill é˜¶æ®µæ‰€æœ‰å±‚çš„ hidden states è¾“å…¥é•¿åº¦ç›¸åŒï¼ˆ1000ï¼‰
2. æ¯å±‚ç‹¬ç«‹ç”Ÿæˆè‡ªå·±çš„ KVï¼Œé•¿åº¦ç›¸åŒï¼ˆ1000ï¼‰
3. å‹ç¼©æ¯”ä¾‹å¯¹æ‰€æœ‰å±‚ç›¸åŒï¼ˆ`compression_ratio=0.5`ï¼‰
4. å› æ­¤æ¯å±‚çš„ `n_kept` ç›¸åŒï¼ˆ500ï¼‰

âŒ **"é€å±‚é€’å‡"çš„ç†è§£æ˜¯é”™è¯¯çš„**ï¼Œé‚£æ··æ·†äº†ï¼š
- **KV Cache**ï¼ˆå„å±‚ç‹¬ç«‹å­˜å‚¨ï¼Œäº’ä¸å½±å“ï¼‰
- **Hidden States**ï¼ˆå±‚é—´ä¼ é€’ï¼Œä¿æŒå®Œæ•´é•¿åº¦ï¼‰
